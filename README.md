# Clawd Voice

**Local voice assistant for OpenClaw** â€” Wake word detection, Speech-to-Text, AI processing, and Text-to-Speech, all running locally (except cloud STT/TTS APIs).

```
Wake Word â†’ VAD Recording â†’ Whisper STT â†’ OpenClaw Agent â†’ ElevenLabs TTS â†’ Speaker
```

## Features

- ğŸ¤ **Wake word detection** with Picovoice Porcupine (offline, local)
- ğŸ”‡ **Voice Activity Detection (VAD)** using Silero VAD (stops recording on silence)
- ğŸ—£ï¸ **Speech-to-Text** via OpenAI Whisper API
- ğŸ¤– **AI processing** through OpenClaw Gateway (local agent orchestration)
- ğŸ”Š **Text-to-Speech** with ElevenLabs streaming API (high-quality voices)
- ğŸ–¥ï¸ **Cross-platform** audio playback (macOS, Linux, Windows)

## Requirements

- **Python 3.10+**
- **Picovoice account** (free tier) â€” [Get key here](https://console.picovoice.ai/)
- **OpenAI API key** (for Whisper STT) â€” [Get key here](https://platform.openai.com/api-keys)
- **ElevenLabs API key** (for TTS) â€” [Get key here](https://elevenlabs.io/)
- **OpenClaw Gateway** running locally â€” [Install OpenClaw](https://github.com/openclaw/openclaw)

### Optional (for certain playback backends)
- **Linux:** `aplay` (ALSA, usually pre-installed) or `ffmpeg` for MP3 support
- **All platforms:** `ffplay` (FFmpeg) if you want to use the ffplay backend

## Installation

1. **Clone the repository:**
   ```bash
   git clone https://github.com/joetomasone/clawd-voice.git
   cd clawd-voice
   ```

2. **Create virtual environment:**
   ```bash
   python3 -m venv .venv
   source .venv/bin/activate  # On Windows: .venv\Scripts\activate
   ```

3. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

4. **Configure:**
   ```bash
   cp config.yaml.example config.yaml
   # Edit config.yaml with your API keys and settings
   ```

5. **Run:**
   ```bash
   python3 main.py
   ```

## Configuration

Edit `config.yaml` to customize:

### Wake Word
```yaml
wake_word: "jarvis"  # Built-in options: jarvis, alexa, computer, hey google, etc.
porcupine_access_key: "YOUR_PICOVOICE_KEY"
```

### Voice Activity Detection (VAD)
```yaml
vad:
  threshold: 0.3              # Speech probability threshold (0-1)
  silence_timeout_sec: 2.0    # Seconds of silence before stopping
  max_recording_sec: 30       # Maximum recording duration
```

### Speech-to-Text (Whisper)
```yaml
stt:
  provider: openai
  openai_api_key: "YOUR_OPENAI_KEY"
  model: whisper-1
```

### OpenClaw Gateway
```yaml
gateway:
  url: "http://localhost:18789"
  token: "YOUR_GATEWAY_TOKEN"
  agent: "clawd"
  session: "agent:clawd:main"
```

### Text-to-Speech (ElevenLabs)
```yaml
tts:
  provider: elevenlabs
  api_key: "YOUR_ELEVENLABS_KEY"
  voice_id: "JBFqnCBsd6RMkjVDRZzb"  # George (British male)
  model: "eleven_turbo_v2_5"
  stability: 0.6
  similarity_boost: 0.8
```

### Audio Settings
```yaml
audio:
  input_device: -1        # -1 = default, or specific device index
  pyaudio_device: -1      # PyAudio device index (for VAD recorder)
  sample_rate: 16000
  chime_on_wake: true
  
  # playback_backend options:
  #   auto = auto-detect platform (default)
  #   afplay = macOS native (WAV, MP3, AAC, etc.)
  #   aplay = Linux ALSA (WAV only, ffmpeg for MP3)
  #   sounddevice = Python library (universal fallback)
  #   ffplay = FFmpeg player (requires ffmpeg)
  playback_backend: auto
```

## Platform Support

| Platform | Default Backend | Notes |
|----------|----------------|-------|
| **macOS** | `afplay` | Native, supports all common formats |
| **Linux** | `aplay` | ALSA (WAV only), auto-converts MP3 via ffmpeg if available, falls back to sounddevice |
| **Windows** | `sounddevice` | Python library, works universally |

### Platform-Specific Notes

**macOS:**
- `.app` bundle and `com.clawd.voice.plist` are macOS-only launch helpers
- Use `launchctl` to run as background service (see `.plist` file)

**Linux:**
- Install `ffmpeg` for MP3 support with aplay: `sudo apt install ffmpeg`
- Or let it fall back to `sounddevice` (pure Python)

**Windows:**
- Uses `sounddevice` + `soundfile` by default (no external dependencies)

## Usage

1. **Start the assistant:**
   ```bash
   python3 main.py
   ```

2. **Say the wake word** (default: "jarvis")

3. **Speak your request** (VAD will auto-detect when you stop talking)

4. **Listen to the response** (text is sent to OpenClaw, response is spoken via TTS)

### Example Session
```
ğŸ¾ Clawd Voice starting up...
  âœ“ Audio backend: afplay
  âœ“ Wake word: 'jarvis'
  âœ“ VAD recorder ready
  âœ“ Whisper STT ready
  âœ“ ElevenLabs TTS ready
  âœ“ Gateway client ready

ğŸ¤ Listening for 'jarvis'... (Ctrl+C to quit)

âš¡ Wake word detected!
ğŸ™ï¸  Listening...
ğŸ“ Transcribing...
   You: What's the weather like today?
ğŸ¤” Thinking...
   Clawd: It's currently 72Â°F and partly cloudy in Tampa.

ğŸ¤ Listening for 'jarvis'...
```

## Troubleshooting

### No audio playback
- Check `playback_backend` in `config.yaml`
- Try switching to `sounddevice` backend (most universal)
- Ensure `sounddevice` and `soundfile` are installed

### Microphone not detected
- List devices: `python3 -c "import pvrecorder; print(pvrecorder.PvRecorder.get_available_devices())"`
- Set `input_device` in `config.yaml` to the correct index

### Wake word not triggering
- Speak clearly and closer to the microphone
- Try different built-in wake words (see [Porcupine docs](https://picovoice.ai/docs/porcupine/))

### OpenClaw connection fails
- Ensure OpenClaw Gateway is running: `openclaw gateway status`
- Check `gateway.url` and `gateway.token` in `config.yaml`

## Development

**Project structure:**
```
clawd-voice/
â”œâ”€â”€ main.py              # Main loop and orchestration
â”œâ”€â”€ wake.py              # Porcupine wake word detector
â”œâ”€â”€ recorder.py          # Silero VAD-gated recorder
â”œâ”€â”€ transcribe.py        # OpenAI Whisper STT
â”œâ”€â”€ speak.py             # ElevenLabs TTS
â”œâ”€â”€ gateway_client.py    # OpenClaw Gateway client
â”œâ”€â”€ audio_player.py      # Cross-platform audio playback
â”œâ”€â”€ config.yaml          # Configuration (not in git, use config.yaml.example)
â”œâ”€â”€ chime.wav            # Wake acknowledgment sound
â”œâ”€â”€ one_moment.wav       # "Processing" acknowledgment
â””â”€â”€ requirements.txt     # Python dependencies
```

## License

MIT License â€” see LICENSE file for details.

## Credits

Built with:
- [Picovoice Porcupine](https://picovoice.ai/) (wake word)
- [Silero VAD](https://github.com/snakers4/silero-vad) (voice activity detection)
- [OpenAI Whisper](https://platform.openai.com/docs/guides/speech-to-text) (STT)
- [ElevenLabs](https://elevenlabs.io/) (TTS)
- [OpenClaw](https://github.com/openclaw/openclaw) (agent orchestration)

---

**Made for Joe's OpenClaw setup** ğŸ¾
